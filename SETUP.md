# Project Setup Instructions

## Install Dependencies

This project requires Python 3.9 or later. Install all dependencies with:

```bash
pip install -r requirements.txt
```

## Dataset Setup

This repository does **not** include raw audio files. Create the following directory structure:

```
data/raw/acapella/
data/raw/non_acapella/
```

Place your `.wav` or `.mp3` audio clips into the appropriate folders. Each clip should be 7â€“15 seconds long.

Processed mel-spectrogram features will be generated automatically the first time the notebook is run and stored in:

```
data/processed/
```

No manual preprocessing is required.

## Running the Classifier

Open the main notebook and execute all cells in order:

```
notebooks/acapella_detector_demo.ipynb
```

The notebook will:

- load the pretrained logistic regression model and scaler
- accept uploaded audio clips
- preprocess them into mel-spectrogram features
- classify each clip as a cappella or non-a cappella
- return a confidence score and optionally display the spectrogram

## Google Drive / Colab Notes (If Applicable)

If running in Google Colab and your dataset is stored on Google Drive, run:

```python
from google.colab import drive
drive.mount('/content/drive')
```

Then update dataset paths if needed. Raw audio data is not included due to copyright restrictions. You must provide your own clips to reproduce the results.

